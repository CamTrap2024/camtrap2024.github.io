---
title: Program
layout: subpage
lang: en
permalink: program/
description: Programm of the workshop
---

<section class="subpage-program">
    <article id="program">
        <h1 class="heading">Program</h1>

        <!-- <h3>Workshop Schedule</h3> -->
        <div class="row">
            <div class="col-md-12">
                <table class="table table-hover table-striped ">
                    <thead>
                        <tr>
                            <th></th>
                            <th>Time</th>
                            <th>Title</th>
                        </tr>
                    </thead>
                    <tbody>
                    {% for schedule in site.data.schedule %}   
                    {% for slot in schedule.slots %}
                    {% assign time_h = slot.time | date: '%s' %}
                    {% assign time_dura = slot.duration | times: 3600 %}
                    {% assign time_end = time_h | date: '%s' | plus: time_dura | round | date: '%s' %}
                    <tr>
                        {% if forloop.first %}
                        <th>{{ schedule.date }}</th>
                        {% else %}
                        <td></td>
                        {% endif %}
                        <td>{{ time_h | date: '%s' | date: '%H:%M' }} - {{ time_end | date: '%s' | date: '%H:%M' }} ({{ time_dura | divided_by: 60 | round }}&prime;)</td>
                        {% if slot.category == "keynote" %}
                            <td class="table-primary">
                        {% elsif slot.category == "break" %}
                            <td>
                        {% elsif slot.category == "papers" %}
                            <td class="table-success">
                        {% elsif slot.category == "tutorial" %}
                            <td class="table-info">
                        {% elsif slot.category == "not used" %}
                            <td class="table-warning">
                        {% elsif slot.category == "social" %}
                            <td class="table-danger">
                        {% else %}
                            <td>
                        {% endif %}
                            {{ slot.title }}
                        </td>
                    </tr>
                    {% endfor %}
                    {% if forloop.last %}
                    {% else %}
                    <tr>
                        <td colspan="3"></td>
                    </tr>
                    {% endif %}
                    {% endfor %}
                </tbody>
                <caption>All workshop schedule times are in CEST. Please note that the schedule is subject to minor changes.</caption>
            </table>
            </div>
        </div>

        <h3>Keynote Speakers</h3>
        <div class="row" id="Cliodhna">
            <div class="col-sm-3">
                <img src="/assets/img/cquigley_square.jpg" alt="Cliodhna Quigley" style="max-width: 100%;">
            </div>
            <div class="col-sm-9">
                <p>
                    <b>Cliodhna Quigley</b> is a cognitive scientist with a focus on data analysis and computational solutions for the study of animal behaviour. Since joining the Fusani lab in Vienna in 2016, she has been involved in developing new approaches for the group to study courtship in birds using videos recorded in laboratory settings and during fieldwork. As well as tracking movements and quantifying behavioural patterns of courting males and choosing females, she also implemented a laboratory system allowing synchronized playback of high-speed video and audio to bird audiences. Her current research interests include the feasability of applying AI models trained on human movement data to data from animals.
                    <br /><br />
                    For additional information please visit her <a href="https://becogbio.univie.ac.at/people/scientific-staff/cliodhna-quigley/"
                        target="_blank">website at the University of Vienna</a>.
                </p>
            </div>
        </div>
        <br />
        <div class="row" id="Robin">
            <div class="col-sm-3">
                <img src="/assets/img/rsandfort_square.jpg" alt="Robin Sandfort" style="max-width: 100%;">
            </div>
            <div class="col-sm-9">
                <p>
                    <b>Robin Sandfort</b> is a wildlife biologist who integrates open sensor systems and open source software for sustainable wildlife management and biodiversity monitoring. He now works with his companies capreolus and micromacro as a conservation technologist bridging the gap between classical biodiversity monitoring and the emerging use of AI in remote sensing, bioacoustics and monitoring of invasive alien species.
                    <br /><br />
                    For additional information please visit his <a href="https://www.capreolus.at"
                        target="_blank">website capreolus.at</a>.
                </p>
            </div>
        </div>
        <br />
        <div class="row" id="Stefano">
            <div class="col-sm-3">
                <img src="/assets/img/smintchev_square.jpg" alt="Stefano Mintchev" style="max-width: 100%;">
            </div>
            <div class="col-sm-9">
                <p>
                    <b>Stefano Mintchev</b> is Assistant Professor of Environmental Robotics at ETH Zurich. He completed his Ph.D. in biorobotics from Scuola Superiore Sant’Anna, Italy in 2014.  During his postdoctoral activity at EPFL he contributed to the field of flying robotics by proposing novel design and manufacturing principles for morpho-functional drones that are inspired by natural flyers. In 2018, Stefano co-founded Foldaway Haptics, where he acted as CTO until April 2020, before joining ETH Zurich with a SNSF Professorial Fellowship. Today, his research focuses on advancing the science and technology of robotics to address the pressing and interconnected challenges of sustainability, climate change, and biodiversity decline.
                    <br /><br />
                    For further information please visit the <a href="https://erl.ethz.ch"
                        target="_blank">Environmental-Robotics-Lab website at ETH Zurich</a>.
                </p>
            </div>
        </div>
        <br />
        <div class="row" id="Claudia">
            <div class="col-sm-3">
                <img src="/assets/img/probst.png" alt="Claudia Probst" style="max-width: 100%;">
            </div>
            <div class="col-sm-9">
                <p>
                    <b>Claudia Probst</b> is a professor and senior researcher at the FH OÖ Campus of Engineering and Natural Sciences in Wels. She began her academic journey studying nutritional sciences at the University of Bonn. Following this, she embarked on a short-term assignment in a mycotoxin research laboratory at the University of Arizona. This position quickly ignited her passion for the field and evolved into a rich personal and professional journey over six years, concluding with a husband, two kids, and a doctorate in Plant Pathology & Microbiology in 2010. Following her doctoral studies, Dr. Probst moved on to the Washington State University, USA. For six years, she held the position of Research Professor, investigating applied, innovative methods of disease control for sweet cherries and hops growing in the US Pacific Northwest. In 2018, Claudia and her family returned to Europe, choosing Austria as her new home. She took up a leadership role in the recently established bachelor’s degree program in Agricultural Technology and Management at the University of Applied Sciences in Upper Austria. Besides her teaching duties, she established the research group D-FARM (Digitalization in Forestry, Agriculture, Research, and Management). This interdisciplinary group brings together expertise in image and data processing, computer science, automation technology, forestry, biotechnology, molecular biology, and plant protection. D-Farm is dedicated to addressing the multi-faceted challenges confronting modern agriculture and forestry, using a comprehensive, scientific approach to digital solution development.                    <br /><br />
                    For further information please visit the <a href="https://pure.fh-ooe.at/en/persons/claudia-probst"
                        target="_blank">website at University of Applied Sciences Upper Austria</a>.
                </p>
            </div>
        </div>
        <br />
        <div class="row" id="Georg">
            <div class="col-sm-3">
                <img src="/assets/img/schneider.png" alt="Georg Schneider" style="max-width: 100%;">
            </div>
            <div class="col-sm-9">
                <p>
                    <b>Georg Schneider</b> is researcher at the University of Applied Sciences Upper Austria and project leader of the "DigiNose" research program. Georg embarked on his academic journey at the University of Applied Sciences in Hagenberg, graduating with a BSc in Software Engineering in 2013 before obtaining his MSc in Human-Centered Computing in 2017. Throughout the course of his career, he has held diverse roles, from a shift leader at a dairy company to critical positions in software development, project leadership, and team management in several renowned companies. He consistently demonstrated competence in process analysis and improvement, software development and architecture, and team leadership. Since 2017, Georg has been a researcher working on Machine Learning System, processes for the autonomous driving of trains, and lately applying his technical expertise to biological questions such as bark beetle control. Parallel to his professional roles, Georg has shared his insights with numerous students as a lecturer at the FH OÖ, teaching subjects including programming in C#, IT fundamentals, and data management. He's also supervised several bachelor theses, bringing his vast knowledge and experience to a new generation of technologists.                    <br /><br />
                    For further information please visit the <a href="https://pure.fh-ooe.at/en/persons/georg-roman-schneider"
                        target="_blank">website at University of Applied Sciences Upper Austria</a>.
                </p>
            </div>
        </div>

        <br />
        <h3>Tutorial Sessions</h3>
        <div class="row" id="Swarovski">
            <div class="col-sm-3">
                <img src="/assets/img/mckenney.png" alt="Danielle McKenney" style="max-width: 100%;">
            </div>
            <div class="col-sm-9">
                <p>
                    <b>Danielle McKenney</b> is a Data Engineer at Swarovski Optik, where she combines her interest in birds and wildlife with her expertise in machine learning. Her background is in mathematics and computer science, with a specialization in data science. At Swarovski Optik, she manages the data infrastructure to support machine learning projects. This includes experimenting with and evaluating different models for integration into the AXVisio, the world’s first smart binoculars. Her talk will explore the process of embedding AI models onto this device. The project assumptions are explored, as well as the complexity of embedded software its dependency on hardware components. Key lessons from the first prototype version are shared, with a focus on the current approach to meet user expectations. In addition to the technical challenges faced in the context of running AI models on an embedded hardware, insights are offered on the increased importance of user experience in AI applications.                     
                    <br /><br />
                    For additional information please visit <a href="https://www.swarovskioptik.com/at/de/jagd/products/binoculars/ax-visio"
                        target="_blank">Swarovski's website</a>.
                </p>
            </div>
        </div>
        <br />
        <div class="row" id="Smartmulticopters">
            <div class="col-sm-3">
                <img src="/assets/img/smc.png" alt="SmartMultiCopters" style="max-width: 100%;">
            </div>
            <div class="col-sm-9">
                <p>
                    Andreas Leitner, Bernhard Wieser and Jürgen Bachbauer are the founders of UAV startup <b>Smartmulticopters</b>. The company specialises in the development and production of UAV platform solutions based on open source flight controllers and software that can be individually configured for different applications.  For example, more than 200 of these drones are already being used successfully for semi-automated wildlife detection. The dual camera system required for this application is equipped with a Raspberry PI to process the sensor data and process the video pipeline for the downlink. By using open source components and open sensor systems, this UAV platforms can be adapted to the specific application. In addition, this product concept is repairable and can be extended for other applications.

                    <br /><br />
                    For additional information please visit <a href="https://smartmulticopters.at/"
                        target="_blank">SmartMultiCopters' homepage</a>.
                </p>
            </div>
        </div>
        <br />
        <div class="row" id="Trapper">
            <div class="col-sm-3">
                <img src="/assets/img/piotr.png" alt="Piotr" style="max-width: 100%;">
            </div>
            <div class="col-sm-9">
                <p>
                    <b>Piotr Tynecki</b> will present TRAPPER, an open-source ecosystem designed to manage camera trapping projects, featuring Citizen Science and Trapper AI extensions. Camera trapping is now a vital tool in ecological research, generating large, complex multimedia datasets. TRAPPER provides a novel solution to these challenges. Unlike other available software solutions, TRAPPER is a fully open-source web application that utilizes spatially enabled data and supports various media types, including both pictures and videos. It facilitates collaborative work on projects, enables data sharing among users (experts and citizens), supports data export in Camtrap DP standard and integrates AI-based object detection and species classification as well as human-based annotation functionality. TRAPPER is  adopted by various institutions and NGOs across Europe and is gaining traction in South America.

                    <br /><br />
                    For additional information please visit <a href="https://gitlab.com/trapper-project" target="_blank">Gitlab page</a>, <a href="https://trapper-project.readthedocs.io/"
                    target="_blank">TRAPPER documentation</a> or the <a href="https://www.youtube.com/@TrapperTrapperAI" target="_blank">TRAPPER AI YouTube channel</a>.
                </p>
            </div>
        </div>

        <br />
        <h3 id="papers">Paper Sessions</h3>
        <div class="row">
            <div class="col-md-12">
                {% for session in site.data.sessions %}   
                <h5 id="{{ session.id }}">{{ session.session }}</h5>
                <table class="table table-hover table-striped ">
                    {% if forloop.first %}
                    <thead>
                        <tr>
                            <th>Title</th>
                            <th>Authors</th>
                        </tr>
                    </thead>
                    {% endif %}
                    <tbody>
                        {% for paper in session.papers %}
                        <tr>
                            <td>{{ paper.title }}</td>
                            <td width="30%">{{ paper.authors }}</td>
                        </tr>
                        {% endfor %}
                    </tbody>
                    {% if forloop.last %}
                        <caption>* indicates corresponding authors.</caption>
                    {% endif %}
                </table>
                {% endfor %}
            </div>
        </div>

        
        <h3>Further Information</h3>
        <div class="row">
            <div class="col-md-12">
            There will be no registration fees for participating on-site or online!
            <br />
            The time slots for each speaker:
            <ul>
                <li>Keynote: 45 minutes</li>
                <li>Tutorial: 30 minutes</li>
                <li>Paper Presentation: 15 minutes</li>
            </ul>
            </div>
        </div>

    </article>
</section>